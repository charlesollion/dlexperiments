{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burger's equation\n",
    "\n",
    "Tools: jax (to install `pip install jax`)\n",
    "Goal: have a first simple 1D model to work with.\n",
    "\n",
    "https://arxiv.org/pdf/1711.10561.pdf\n",
    "\n",
    "Burger's equation becomes:\n",
    "$$\n",
    "u_t + u \\times u_x − (0.01/π)u_{xx} = 0, x ∈ [−1, 1], t ∈ [0, 1], \\\\\n",
    "u(0, x) = − sin(πx), \\\\\n",
    "u(t, −1) = u(t, 1) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, jacfwd, jacrev\n",
    "from jax import random\n",
    "\n",
    "# Jax uses a state based random number generation \n",
    "# process, which is much less error prone than (hidden) \n",
    "# stateless cases in tensorflow, pytorch, but more \n",
    "# cumbersome. You need to split the key into 2 parts \n",
    "# and use subparts to generate your random numbers.\n",
    "key = random.PRNGKey(0)\n",
    "key, subkey = random.split(key)\n",
    "\n",
    "W = random.normal(subkey, (2, 1))\n",
    "b = np.zeros(1)\n",
    "params = (W, b)\n",
    "\n",
    "# Simple u function: only 3 params!\n",
    "def u(t, x, params):\n",
    "    W, b = params\n",
    "    xandt = np.concatenate((t, x))\n",
    "    return np.dot(xandt, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0 border condition\n",
    "def u0(x):\n",
    "    return - np.sin(np.pi * x)\n",
    "\n",
    "# u_xx\n",
    "def hessian(f, index_derivation=0):\n",
    "    return jacfwd(jacrev(f,index_derivation),index_derivation)\n",
    "\n",
    "# function f could be defined with grad instead of jacobians\n",
    "# because we only have scalars here.\n",
    "def f(t_, x_, params_):\n",
    "    u_out = u(t_, x_, params_)\n",
    "    u_t = jacfwd(u,0)(t_, x_, params_)\n",
    "    u_x = jacfwd(u,1)(t_, x_, params_)\n",
    "    u_xx = hessian(u,1)(t_, x_, params_)\n",
    "    f_out = u_t + u_out*u_x - (0.01/np.pi)*u_xx\n",
    "    return f_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test point\n",
    "x_test = np.ones(1) * 0.25\n",
    "t_test = np.ones(1) * 0.25\n",
    "\n",
    "u(t_test, x_test, params), f(t_test, x_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_f(t_, x_, params_):\n",
    "    return np.mean(f(t_, x_, params_)**2)\n",
    "\n",
    "mse_f(t_test, x_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_u(t_, x_, u_, params_):\n",
    "    return np.mean((u_ - u(t_, x_, params_))**2)\n",
    "\n",
    "mse_u(np.ones(1), np.zeros(1), np.zeros(1), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t_, x_, u_, params_):\n",
    "    return mse_u(t_, x_, u_, params_) + mse_f(t_, x_, params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_params(t_, x_, u_, params_):\n",
    "    return grad(mse, 3)(t_, x_, u_, params_)\n",
    "\n",
    "# Will output 2 objects: gradients wrt W and b\n",
    "gradient_params(np.ones(1), np.zeros(1), np.zeros(1), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and learning\n",
    "\n",
    "We build $N_u = 100$ boundary data points as mentionned in the paper. Half of them for $t=0$, the other half for $x= \\pm 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_u = 100\n",
    "data = []\n",
    "\n",
    "for i in range(N_u):\n",
    "    x_data,t_data,u_data = 0.0, 0.0, 0.0\n",
    "    key, subkey = random.split(key)\n",
    "    if  random.uniform(subkey)>0.5:\n",
    "        t_data = 0\n",
    "        key, subkey = random.split(key)\n",
    "        x_data = random.uniform(subkey)*2-1\n",
    "        u_data = u0(x_data)\n",
    "        # t=0, u= -sin(pi x)\n",
    "    else:\n",
    "        key, subkey = random.split(key)\n",
    "        t_data = random.uniform(subkey)\n",
    "        key, subkey = random.split(key)\n",
    "        x_data = (random.uniform(subkey)>0.5)*2-1\n",
    "        u_data = 0\n",
    "    data.append([x_data,t_data,u_data])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Numpy way to build data (no loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = random.split(key)\n",
    "data_type = random.uniform(key, (100,))>0.5\n",
    "key, subkey1, subkey2, subkey3 = random.split(key, 4)\n",
    "x_data = data_type * (random.uniform(subkey1, (100,))*2.0-1.0)+ \\\n",
    "    (1-data_type) * ((random.uniform(subkey2, (100,))>0.5)*2.0-1.0)\n",
    "t_data = data_type * 0 + ((1-data_type) * random.uniform(subkey3, (100,)))\n",
    "u_data = data_type * u0(x_data)\n",
    "\n",
    "x_data, t_data, u_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: \n",
    "- sample $N_f$ points for evaluation of $f$ \n",
    "- build a real neural network\n",
    "- training loop\n",
    "- display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle KPP\n",
    "\n",
    "$$\n",
    "\\begin{equation} \\label{eq:KPP_homog}\n",
    "  \\partial_t u(t,x) = D \\Delta u + r u (1 - u), \\ t>0, \\ x\\in \\Omega \\subset \\mathbb{R}^2,\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "avec la condition initiale $u(0,\\cdot)=u_0(\\cdot)$ dans $\\Omega$ et la condition au bord $u(t,\\cdot )=0$ sur $\\partial\\Omega$ pour tout $t>0$. On pourra prendre $\\Omega=(0,1)\\times(0,1)$.\n",
    "\n",
    "To be continued."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
