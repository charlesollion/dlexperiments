{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click to open in Colab to access a GPU environment: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/charlesollion/dlexperiments/blob/master/Going%20Further%20with%20VAEs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going further with VAEs\n",
    "\n",
    "Building on the simple VAE exemple, this notebook is organized as follows:\n",
    "1. Convolutional VAE: a stronger architecture, with a few computational tricks to make it work\n",
    "2. [$\\beta$-VAE](https://openreview.net/forum?id=Sy2fzU9gl), increasing the importance of the KL term\n",
    "3. Better parametrization of the output distribution\n",
    "4. Conditional VAEs, typically conditionning the modeled density by a class\n",
    "5. Exploring [Importance weighted Autoencoders](https://arxiv.org/abs/1509.00519) (IWAE)\n",
    "6. Final thoughts: can VAEs efficiently model simple toy datasets (distributions)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i in range(0, 18):\n",
    "    plt.subplot(3, 6, i + 1)\n",
    "    plt.imshow(x_train[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "x_train = np.expand_dims(x_train.astype('float32') / 255., -1)\n",
    "x_test = np.expand_dims(x_test.astype('float32') / 255., -1)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad\n",
    "from jax import random\n",
    "rand_key = random.PRNGKey(1)\n",
    "from jax.experimental import stax # neural network library\n",
    "from jax.experimental.stax import Dense, Relu, Sigmoid, Selu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convolutional VAE\n",
    "\n",
    "A convolutional VAE will make use of the spatial structure of the images, and rely on convolutions instead of Dense layers, both in the encoder and decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental.stax import Conv, BatchNorm, MaxPool, Flatten\n",
    "\n",
    "input_dim = x_train.shape[-1]\n",
    "hidden_dim = 128\n",
    "latent_dim = 8\n",
    "\n",
    "encoder_init, encoder_fn = stax.serial(\n",
    "    Conv(32, (3, 3), padding=\"SAME\"), BatchNorm(), Selu, \n",
    "    Conv(32, (3, 3), padding=\"SAME\"), BatchNorm(), Selu, \n",
    "    MaxPool((2,2), (2,2)),\n",
    "    Conv(64, (3, 3), padding=\"SAME\"), BatchNorm(), Selu, \n",
    "    Conv(64, (3, 3), padding=\"SAME\"), BatchNorm(), Selu, \n",
    "    MaxPool((2,2), (2,2)),\n",
    "    Flatten, Dense(latent_dim*2)\n",
    ")\n",
    "\n",
    "#initialize the parameters\n",
    "rand_key, key = random.split(rand_key)\n",
    "out_shape, params_enc = encoder_init(rand_key, (-1, 28, 28, 1))\n",
    "\n",
    "def count_params(params):\n",
    "    count = 0\n",
    "    for param_tuple in params:\n",
    "        for param in param_tuple:\n",
    "            count += np.prod(param.shape)\n",
    "    return count\n",
    "\n",
    "params_num = len(params_enc)\n",
    "print(f\"Number of param objects: {params_num}, total number of params: {count_params(params_enc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time z = jit(encoder_fn)(params_enc, x_train[0:10])\n",
    "%time z = encoder_fn(params_enc, x_train[0:10])\n",
    "print(f\"output shape: {z.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(rand_key, z_mean, z_log_var):\n",
    "    epsilon = random.normal(rand_key, shape=z_mean.shape)\n",
    "    return z_mean + jnp.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "fast_sample = jit(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = encoder_fn(params_enc, x_train[0:3])\n",
    "d = z.shape[-1]//2\n",
    "z_mean, z_log_var = z[:, :d], z[:,d:]\n",
    "rand_key, key = random.split(rand_key)\n",
    "samples = sample(key, z_mean, z_log_var)\n",
    "print(f\"z shape (concatenation of z_mean and z_log_var) : {z.shape}, samples shape: {samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a Upsample and Reshape layer, we can build them using the stax layer API. \n",
    "# A layer is a tuple: (init_fun, apply_fun): \n",
    "# init_fun creates the parameters matrices and return the params and output shape\n",
    "# apply_fun is the mathematical operation\n",
    "\n",
    "def Upsample():\n",
    "    def init_fun(rng, input_shape):\n",
    "        ish = input_shape\n",
    "        assert len(ish) == 4\n",
    "        return ((ish[0], ish[1]*2, ish[2]*2, ish[3]), ())\n",
    "    \n",
    "    def apply_fun(params, inputs, **kwargs):\n",
    "        inputs = inputs.transpose((0,3,1,2))\n",
    "        upx = jnp.kron(inputs, jnp.ones((2,2)))\n",
    "        return upx.transpose((0,2,3,1))\n",
    "    \n",
    "    return init_fun, apply_fun\n",
    "\n",
    "def Reshape(shape):\n",
    "    def init_fun(rng, input_shape):\n",
    "        return input_shape[:-1] + shape, ()\n",
    "\n",
    "    def apply_fun(params, inputs, **kwargs):\n",
    "        return inputs.reshape(inputs.shape[:-1] + shape)\n",
    "    \n",
    "    return init_fun, apply_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reshape((7, 7, 64))[1]((), jnp.ones([2,7*7*64])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Upsample()[1]([], x_train[0:3])[0,:,:,0], cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_init, decoder_fn = stax.serial(\n",
    "    Dense(64*7*7), Reshape((7,7,64)),\n",
    "    Upsample(), \n",
    "    Conv(32, (3, 3), padding=\"SAME\"), BatchNorm(), Selu, \n",
    "    Conv(32, (3, 3), padding=\"SAME\"), BatchNorm(), Selu, \n",
    "    Upsample(),\n",
    "    Conv(64, (3, 3), padding=\"SAME\"), BatchNorm(), Selu, \n",
    "    Conv(64, (3, 3), padding=\"SAME\"), BatchNorm(), Selu, \n",
    "    Conv(1, (3, 3), padding=\"SAME\"), Sigmoid\n",
    ")\n",
    "\n",
    "#initialize the parameters\n",
    "rand_key, key = random.split(rand_key)\n",
    "out_shape, params_dec = decoder_init(rand_key, (-1, latent_dim))\n",
    "\n",
    "params = params_enc + params_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of params: {count_params(params_dec)}\")\n",
    "decoder_fn(params_dec, samples).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bernoulli Output distribution\n",
    "\n",
    "Previously, we assumed that the data is valued on $\\{0, 1\\}$ and used a Bernoulli distribution and the associated crossentropy loss.\n",
    "\n",
    "This is very common and the problem is pointed by [this paper](https://arxiv.org/pdf/1907.06845.pdf) which proposes a different parametrization of the output instead of parametrizing a Bernoulli likelihood. As the pixel data is $[0, 1]$ valued, they introduce a continuous Bernoulli distribution, which is a normalized Bernoulli:\n",
    "$$p(x|λ) = C(λ) λ^x (1 − λ)^{1−x}$$\n",
    "\n",
    "See the paper for details about the $C(λ)$. The following cell computes the log of this normalization factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-6\n",
    "\n",
    "@jit\n",
    "def cont_bern_log_norm(l):\n",
    "    # computes the log normalizing constant of a continuous Bernoulli distribution in a numerically stable way.\n",
    "    # When l is in [lower_lim, upper_lim], we cut it to lower_lim\n",
    "    lower_lim, upper_lim =0.49, 0.51\n",
    "    \n",
    "    cut_l = jnp.where(jnp.logical_or(l < lower_lim, l > upper_lim), l, lower_lim * jnp.ones_like(l))\n",
    "    log_norm = jnp.log(jnp.abs(2.0 * jnp.arctanh(jnp.abs(1 - 2.0 * cut_l) - EPSILON))) - jnp.log(jnp.abs(1 - 2.0 * cut_l) + EPSILON)\n",
    "    return log_norm\n",
    "\n",
    "xent = jit(lambda x, xt: - jnp.sum(xt * jnp.log(x + EPSILON) + \n",
    "                                   (1-xt)*jnp.log(1-x+EPSILON) + \n",
    "                                   cont_bern_log_norm(x), axis=(1,2,3)))\n",
    "kl = jit(lambda z_mean, z_log_var: - 0.5 * jnp.sum(1 + z_log_var - z_mean ** 2 - \n",
    "                                                   jnp.exp(z_log_var), axis=(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the normalizing factor can be seen below as a function of lambda\n",
    "plt.plot(jnp.linspace(0,1,100), cont_bern_log_norm(jnp.linspace(0,1,100)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using standard Bernoulli, we had the property that the output of our decoder, i.e. parameters $\\lambda_i$ of the Bernoulli distribution, where equal to the expected value of the output:\n",
    "\n",
    "$$X \\sim \\mathcal{B}(\\lambda) \\implies \\mathbb{E}[X] = \\lambda$$ for each cooridinate of $X$ and $\\lambda$.\n",
    "\n",
    "To sample from a continuous Bernoulli distribution, we will have to compute the following:\n",
    "\n",
    "$$X \\sim \\mathcal{CB}(\\lambda) \\implies \\mathbb{E}[X] = \\frac{\\lambda}{2\\lambda - 1} + \\frac{1}{2tanh^{-1}(1-2\\lambda)}$$\n",
    "\n",
    "if $\\lambda \\neq 0.5$, otherwise $\\mathbb{E}[X] = 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_from_lambda(l):\n",
    "    # Computes the mean of output distribution given lambda parameter, in a numerically stable way\n",
    "    lower_lim, upper_lim =0.49, 0.51\n",
    "    \n",
    "    cut_l = jnp.where(jnp.logical_or(l < lower_lim, l > upper_lim), l, lower_lim * jnp.ones_like(l))\n",
    "    mean = cut_l / (2.0 * cut_l - 1.0) + 1.0 / (2.0 * jnp.arctanh(1.0 - 2.0 * cut_l))\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the expected output as a function of lambda\n",
    "plt.plot(jnp.linspace(0,1,100), mean_from_lambda(jnp.linspace(0,1,100)))\n",
    "plt.plot(jnp.linspace(0,1,100), jnp.linspace(0,1,100), ls=\"dashed\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder function class prior on image generation, before training\n",
    "rand_key, key = random.split(key)\n",
    "z = random.normal(key, shape=(1,latent_dim))\n",
    "generated = decoder_fn(params_dec, z)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mean_from_lambda(generated).reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. $\\beta$ - VAE\n",
    "\n",
    "- [This paper](https://openreview.net/forum?id=Sy2fzU9gl) introduce a minimal modification of the VAE loss, by scaling the KL, with usually $\\beta \\gt 1$, to increase the weight of the KL term in the loss. This $\\beta$ balances latent channel capacity and independence constraints with reconstruction accuracy. They show that this modification is sound and not just a trick, however it adds a new hyperparameter to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-6\n",
    "beta = 2.0\n",
    "\n",
    "@jit\n",
    "def vae_loss(rand_key, params, x):\n",
    "    latent = jit(encoder_fn)(params[0:params_num], x)\n",
    "    d = latent.shape[-1]//2\n",
    "    z_mean, z_log_var = latent[:, :d], latent[:,d:]\n",
    "    z_sample = sample(rand_key, z_mean, z_log_var)\n",
    "    x_rec = jit(decoder_fn)(params[params_num:], z_sample)\n",
    "    \n",
    "    xent_loss = xent(x_rec, x)\n",
    "    kl_loss = kl(z_mean, z_log_var)\n",
    "    return jnp.mean(xent_loss + beta * kl_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time vae_loss(rand_key, params, x_train[0:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the VAE\n",
    "\n",
    "The following cells:\n",
    "    - reinitialize parameters\n",
    "    - initialize an Adam optimizer\n",
    "    - run a batch training over 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may run this cell to reinit parameters if needed\n",
    "_, params_enc = encoder_init(rand_key, (-1, 28,28,1))\n",
    "_, params_dec = decoder_init(rand_key, (-1, latent_dim))\n",
    "params = params_enc + params_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import stax, optimizers\n",
    "\n",
    "data_size = x_train.shape[0]\n",
    "batch_size = 32\n",
    "learning_rate = 0.003\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(learning_rate)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(key, batch, opt_state):\n",
    "    params = get_params(opt_state)\n",
    "    value_and_grad_fun = jit(jax.value_and_grad(lambda params, x: vae_loss(key, params, x)))\n",
    "    loss, grads = value_and_grad_fun(params, batch)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be long! \n",
    "subset_train_num = 100\n",
    "\n",
    "for epochs in range(1):\n",
    "    rand_key, key = random.split(rand_key)\n",
    "    permutation = random.permutation(key, data_size)\n",
    "    for i in range(min(data_size // 32 - 1, subset_train_num)):\n",
    "        batch = x_train[permutation[i * 32:(i+1)*32]]\n",
    "        rand_key, key = random.split(rand_key)\n",
    "        opt_state, loss = update(key, batch, opt_state)\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_params(opt_state)\n",
    "rand_key, key = random.split(key)\n",
    "z = random.normal(key, shape=(1,latent_dim))\n",
    "generated = decoder_fn(params[params_num:], z)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mean_from_lambda(generated).reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D plot of the image classes in the latent space\n",
    "\n",
    "We can also use the encoder to set the visualize the distribution of the test set in the 2D latent space of the VAE model. In the following the colors show the true class labels from the test samples.\n",
    "\n",
    "Note that the VAE is an unsupervised model: it did not use any label information during training. However we can observe that the 2D latent space is largely structured around the categories of images used in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_labels = {0: \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", \n",
    "                5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "x_test_encoded = encoder_fn(params[0:params_num], x_test)\n",
    "pca = PCA(n_components=2)\n",
    "encoded_pca_x=pca.fit_transform(x_test_encoded[:,:latent_dim])\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(encoded_pca_x[:, 0], encoded_pca_x[:, 1], c=y_test,\n",
    "            cmap=plt.cm.tab10)\n",
    "\n",
    "cb = plt.colorbar()\n",
    "cb.set_ticks(list(id_to_labels.keys()))\n",
    "cb.set_ticklabels(list(id_to_labels.values()))\n",
    "cb.update_ticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D panel view of samples from the VAE manifold\n",
    "\n",
    "The following linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian to produce values of the latent variables z. This makes it possible to use a square arangement of panels that spans the gaussian prior of the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15  # figure with 15x15 panels\n",
    "img_size = 28\n",
    "figure = np.zeros((img_size * n, img_size * n))\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n)).astype(np.float32)\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n)).astype(np.float32)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        # z_sample = np.array([[xi, yi]])  # uncomment if latent_dim = 2\n",
    "        z_sample = np.dot(np.array([[xi,yi]]), np.array(pca.components_))\n",
    "        x_decoded = mean_from_lambda(decoder_fn(params[params_num:], z_sample))\n",
    "        img = x_decoded[0].reshape(img_size, img_size)\n",
    "        figure[i * img_size: (i + 1) * img_size,\n",
    "               j * img_size: (j + 1) * img_size] = img\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simpler dataset\n",
    "\n",
    "Up to now, we used the VAE on complex structured data (Fashion MNIST), and it can be seen as a dimensionality reduction method, which aims at building a coherent, disantangled latent space.\n",
    "\n",
    "The following explores how a VAE can capture the distribution of toy datasets, instead of high dimensional and heavily correlated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eightgaussian(n_points):\n",
    "    \"\"\"\n",
    "     Returns the eight gaussian dataset.\n",
    "    \"\"\"\n",
    "    n = np.random.randint(0,8, n_points)\n",
    "    noisex = np.random.normal(size=(n_points)) * 0.2\n",
    "    noisey = np.random.normal(size=(n_points)) * 0.2\n",
    "    x_centers,y_centers = [np.cos(n* np.pi/4.0) * 5 + noisex, np.sin(n* np.pi/4.0) * 5 + noisey]\n",
    "    return np.vstack((x_centers,y_centers)).T\n",
    "            \n",
    "X = eightgaussian(1000)\n",
    "X.shape\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X[:,0], X[:,1], s=1);\n",
    "plt.axis('square');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = X.shape[-1]\n",
    "hidden_dim = 512\n",
    "latent_dim = 2\n",
    "k_samples = 1\n",
    "beta = 4.0\n",
    "\n",
    "encoder_init, encoder_fn = stax.serial(\n",
    "    Dense(hidden_dim), Selu, Dense(hidden_dim), Selu, Dense(hidden_dim), Selu, Dense(latent_dim * 2))\n",
    "\n",
    "#initialize the parameters\n",
    "rand_key, key = random.split(rand_key)\n",
    "out_shape, params_enc = encoder_init(rand_key, (-1, input_dim))\n",
    "\n",
    "def sample(rand_key, z_mean, z_log_var, k_samples):\n",
    "    epsilon = random.normal(rand_key, shape=(k_samples,) + z_mean.shape)\n",
    "    return z_mean + jnp.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "fast_sample = jit(sample)\n",
    "\n",
    "decoder_init, decoder_fn = stax.serial(\n",
    "    Dense(hidden_dim), Selu, Dense(hidden_dim), Selu, Dense(hidden_dim), Selu, Dense(input_dim))\n",
    "\n",
    "#initialize the parameters\n",
    "rand_key, key = random.split(rand_key)\n",
    "out_shape, params_dec = decoder_init(rand_key, (-1, latent_dim))\n",
    "\n",
    "params_enc_num = len(params_enc)\n",
    "params = params_enc + params_dec\n",
    "\n",
    "EPSILON = 1e-6\n",
    "l2 = jit(lambda x, y: jnp.sum((x - y)**2, axis=-1))\n",
    "kl = jit(lambda z_mean, z_log_var: - 0.5 * jnp.sum(1 + z_log_var - z_mean ** 2 - \n",
    "                                                   jnp.exp(z_log_var), axis=-1))\n",
    "\n",
    "@jit\n",
    "def vae_loss(rand_key, params, x):\n",
    "    latent = jit(encoder_fn)(params[0:params_enc_num], x)\n",
    "    d = latent.shape[-1]//2\n",
    "    z_mean, z_log_var = latent[:, :d], latent[:,d:]\n",
    "    z_sample = sample(rand_key, z_mean, z_log_var, k_samples)\n",
    "    x_rec = jit(decoder_fn)(params[params_enc_num:], z_sample)\n",
    "    l2_loss = l2(x_rec, x)\n",
    "    kl_loss = kl(z_mean, z_log_var)\n",
    "    loss = jnp.mean(l2_loss + beta * kl_loss) \n",
    "    return loss\n",
    "    \n",
    "\n",
    "from jax.experimental import stax, optimizers\n",
    "\n",
    "data_size = X.shape[0]\n",
    "batch_size = 32\n",
    "learning_rate = 0.0003\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(learning_rate)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "@jit\n",
    "def update(key, batch, opt_state):\n",
    "    params = get_params(opt_state)\n",
    "    value_and_grad_fun = jit(jax.value_and_grad(lambda params, x: vae_loss(key, params, x)))\n",
    "    loss, grads = value_and_grad_fun(params, batch)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return opt_state, loss\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 1000\n",
    "data_generator = (X[np.random.choice(X.shape[0], 32)] for _ in range(iters))\n",
    "\n",
    "for epochs in range(iters):\n",
    "    batch = X[i * 32:(i+1)*32]\n",
    "    rand_key, key = random.split(rand_key)\n",
    "    opt_state, loss = update(key, next(data_generator), opt_state)\n",
    "    losses.append(loss)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space analysis\n",
    "\n",
    "below : means (blue) and samples (red) of encoded dataset.\n",
    "\n",
    "Note that the latent space has the same shape as the original data (simply scaled), one of the reason of this is that we chose 2D latent space, which is the same as data dimensionality. Maybe this choice of parametrization of latent space was not good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_params(opt_state)\n",
    "params_enc, params_dec = params[0:params_enc_num], params[params_enc_num:]\n",
    "x_encoded = np.asarray(encoder_fn(params_enc, X[:]))\n",
    "plt.figure(figsize=(7, 7))\n",
    "z_mean, z_log_var = x_encoded[:,0:latent_dim], x_encoded[:,latent_dim:]\n",
    "rand_key, key = random.split(rand_key)\n",
    "z_sample = sample(rand_key, z_mean, z_log_var, k_samples)\n",
    "z_sample = np.reshape(z_sample, (k_samples * x_encoded.shape[0],latent_dim))\n",
    "plt.scatter(z_sample[:, 0], z_sample[:, 1], s=1, c=\"r\")\n",
    "plt.scatter(x_encoded[:, 0], x_encoded[:, 1], s=2, c=\"b\")\n",
    "plt.show()\n",
    "print(f\"average of predicted latent variances on dataset: {np.mean(np.exp(z_log_var[:,0]/2)):.2f}, {np.mean(np.exp(z_log_var[:,1]/2)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recontructed samples vs train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = decoder_fn(params_dec, z_mean)\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=1, c=\"b\")\n",
    "plt.scatter(generated[:, 0], generated[:, 1], s=1, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input distribution vs sampled distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_key, key = random.split(rand_key)\n",
    "z = random.normal(key, shape=(5000,latent_dim))\n",
    "generated = np.asarray(decoder_fn(params_dec, z))\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=1, c=\"b\")\n",
    "plt.scatter(generated[:, 0], generated[:, 1], s=2, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kde\n",
    "nbins = 100\n",
    "k = kde.gaussian_kde(generated.T)\n",
    "xi, yi = np.mgrid[-6:6:nbins*1j, -6:6:nbins*1j]\n",
    "zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "k = kde.gaussian_kde(X.T)\n",
    "xio, yio = np.mgrid[-6:6:nbins*1j, -6:6:nbins*1j]\n",
    "zio = k(np.vstack([xio.flatten(), yio.flatten()]))\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(xi, yi, zi.reshape(xi.shape))\n",
    "plt.title(\"VAE distribution\")\n",
    "plt.axis('off');\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(xio, yio, zio.reshape(xio.shape))\n",
    "plt.title(\"original distribution\")\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance Weighted Autoencoders (IWAE)\n",
    "\n",
    "The idea is simply to sample several latent individuals from the gaussian distribution instead of a single one. Sample $\\{z_i\\}^k \\sim q_\\phi(z|x)$. The aim is to get a more accurate loss which represents better the distribution instead of a single point MC estimate of $\\mathbb{E} q(z|x)$\n",
    "\n",
    "$$\\mathcal{L}_k = \\sum_i^k  \\tilde{w_i} \\nabla_θ [log p(x, z_i) - log q(z_i|x)]$$\n",
    "\n",
    "$$w_i = \\frac{p(x, z_i)}{q(z_i|x)} ; \\tilde{w_i} = \\frac{w_i}{\\sum_i^k  w_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_samples = 10\n",
    "\n",
    "# Sample now has an additional parameter k_samples\n",
    "def sample(rand_key, z_mean, z_log_var, k_samples):\n",
    "    epsilon = random.normal(rand_key, shape=(k_samples,) + z_mean.shape)\n",
    "    return z_mean + jnp.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "@jit\n",
    "def vae_loss(rand_key, params, x):\n",
    "    latent = jit(encoder_fn)(params[0:params_num], x)\n",
    "    z_mean, z_log_var = latent[:, :latent_dim], latent[:,latent_dim:]\n",
    "    z_sample = sample(rand_key, z_mean, z_log_var, k_samples)\n",
    "    \n",
    "    # decoding applies to each of the samples\n",
    "    x_rec = jit(decoder_fn)(params[params_num:], z_sample)\n",
    "    \n",
    "    # these terms apply to each of the samples\n",
    "    l2_loss = l2(x, x_rec)\n",
    "    kl_loss = kl(z_mean, z_log_var)\n",
    "    \n",
    "    # softmax of the log_w_i corresponds to the normalized weights\n",
    "    log_w_i = l2_loss + kl_loss\n",
    "    normalized_w_i = jax.lax.stop_gradient(jax.nn.softmax(log_w_i, axis=0))\n",
    "    \n",
    "    weighted_sum = (normalized_w_i * (l2_loss + kl_loss)).sum(axis=0)\n",
    "    \n",
    "    # average over the batch\n",
    "    loss = jnp.mean(weighted_sum) \n",
    "    return loss\n",
    "\n",
    "from jax.experimental import stax, optimizers\n",
    "\n",
    "data_size = X.shape[0]\n",
    "batch_size = 32\n",
    "learning_rate = 0.0003\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(learning_rate)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "@jit\n",
    "def update(key, batch, opt_state):\n",
    "    params = get_params(opt_state)\n",
    "    value_and_grad_fun = jit(jax.value_and_grad(lambda params, x: vae_loss(key, params, x)))\n",
    "    loss, grads = value_and_grad_fun(params, batch)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return opt_state, loss\n",
    "\n",
    "losses = []\n",
    "\n",
    "iters = 1000\n",
    "data_generator = (X[np.random.choice(X.shape[0], 32)] for _ in range(iters))\n",
    "\n",
    "for epochs in range(iters):\n",
    "    batch = X[i * 32:(i+1)*32]\n",
    "    rand_key, key = random.split(rand_key)\n",
    "    opt_state, loss = update(key, next(data_generator), opt_state)\n",
    "    losses.append(loss)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a new stax layer that implements a Gelu activation function https://arxiv.org/abs/1606.08415\n",
    "Gelu = (lambda rng, input_shape: (input_shape, ()), \n",
    "        jit(lambda params, inputs: inputs * jax.nn.sigmoid(1.702*inputs))\n",
    "       )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
