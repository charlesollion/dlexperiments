{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5fU0bcRFM7B"
   },
   "source": [
    "# Uncertainty in DL: MC-Dropout\n",
    "\n",
    "Click to run on colab (if you're not already there): [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/charlesollion/dlexperiments/blob/master/6-Bayesian-DL/MCdropout_pytorch.ipynb) \n",
    "\n",
    "This session aims at understanding and implementing Monte Carlo Dropout, as described in [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning\n",
    "](https://arxiv.org/abs/1506.02142).\n",
    "\n",
    "![](https://github.com/charlesollion/dlexperiments/raw/master/6-Bayesian-DL/BDLworkflow.png)\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "If you're interested in the Keras/Tensorflow version, please consider this instead:\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/charlesollion/dlexperiments/blob/master/6-Bayesian-DL/BayesianDeepWine.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJcfG-w_FM7H"
   },
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If on colab, you may download the dataset running this cell\n",
    "!wget https://github.com/charlesollion/dlexperiments/blob/master/6-Bayesian-DL/X_data.npy?raw=true -O X_data.npy\n",
    "!wget https://github.com/charlesollion/dlexperiments/blob/master/6-Bayesian-DL/y_data.npy?raw=true -O y_data.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJcfG-w_FM7H"
   },
   "source": [
    "We use the [Wine Quality](https://archive.ics.uci.edu/ml/datasets/wine+quality)\n",
    "dataset.\n",
    "We use the red wine subset, which contains 4,898 examples.\n",
    "The dataset has 11 numerical physicochemical features of the wine, and the task is to predict the wine quality, which is a score between 0 and 10.\n",
    "\n",
    "While the experts gave integer scores, we will first consider them as continuous values between 0 and 10 and treat this as a regression task, for simplicity and easy interpretation of confidence intervals. To make the data more continous, we add a small observation noise to `y`.\n",
    "\n",
    "We could consider instead consider a classification task, or many different things here, but that's not the point of this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYDrwmZTFM7K"
   },
   "source": [
    "### Create training and evaluation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06fXwfRCFM7Q"
   },
   "source": [
    "Let's split the wine dataset into training and test sets, with 85% and 15% of\n",
    "the examples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# X has 11 continuous inputs\n",
    "# y is treated as a continous rating between 0 and 9\n",
    "FEATURE_NAMES = [\n",
    "    \"fixed acidity\", \"volatile acidity\", \"citric acid\",\n",
    "    \"residual sugar\", \"chlorides\", \"free sulfur dioxide\",\n",
    "    \"total sulfur dioxide\", \"density\", \"pH\",\n",
    "    \"sulphates\", \"alcohol\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load data\n",
    "all_X_data = np.load(\"./X_data.npy\")\n",
    "all_y_data = np.load(\"./y_data.npy\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X_data, all_y_data, test_size=0.15, random_state=42)\n",
    "\n",
    "# add a bit of noise to y_train\n",
    "y_train = y_train + np.random.normal(0,0.2, size=y_train.shape)\n",
    "\n",
    "# mean = 0 ; standard deviation = 1.0\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# transform to torch tensor\n",
    "tensor_X_train = torch.from_numpy(X_train).float().to(device) \n",
    "tensor_y_train = torch.from_numpy(y_train).float().to(device) \n",
    "tensor_X_test = torch.from_numpy(X_test).float().to(device) \n",
    "tensor_y_test = torch.from_numpy(y_test).float().to(device) \n",
    "\n",
    "# build dataset and dataloader torch objects\n",
    "dataset_train = TensorDataset(tensor_X_train, tensor_y_train)\n",
    "dataset_test = TensorDataset(tensor_X_test, tensor_y_test)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUEGoFbJFM7P"
   },
   "source": [
    "## Baseline: Standard neural network\n",
    "\n",
    "We create a standard deterministic neural network model as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qyqun6Ch2IaQ"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BaselineMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(BaselineMLP, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden_layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.out_layer = nn.Linear(hidden_dim, 1)\n",
    "        self.act = torch.relu\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # First layer\n",
    "        h = self.hidden_layer1(inputs)\n",
    "        h = self.act(h)\n",
    "        # Second layer\n",
    "        h = self.hidden_layer2(h)\n",
    "        h = self.act(h)\n",
    "        output = self.out_layer(h)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-yBAJje3LEd"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, num_epochs):\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.003, weight_decay=1e-5)\n",
    "    loss = torch.nn.MSELoss()\n",
    "    losses = []\n",
    "    model.train()\n",
    "    for e in tqdm(range(num_epochs)):\n",
    "        for x, y in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss_value = loss(model(x), y)\n",
    "            loss_value.backward()\n",
    "            losses.append(loss_value.detach().cpu().item())\n",
    "            optimizer.step()\n",
    "    return losses\n",
    "\n",
    "\n",
    "def eval_model(model):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    for x,y in dataloader_test:\n",
    "        y_hat = model(x)\n",
    "        errors.append(((torch.squeeze(y_hat) - torch.squeeze(y))**2).detach().cpu().numpy())\n",
    "  \n",
    "    rmse = np.sqrt(np.mean(np.concatenate(errors, axis=None)))\n",
    "    return round(rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smdJBd6q287-"
   },
   "outputs": [],
   "source": [
    "baseline_model = BaselineMLP(11, 32).to(device)\n",
    "baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.numel() for p in baseline_model.parameters()]\n",
    "# hidden layer W, hidden layer b, output layer W, output layer b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline evaluations\n",
    "\n",
    "Let's see the untrained model RMSE, and then a very stupid constant model (just predicting the mean of `y_train`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = eval_model(baseline_model)\n",
    "print(f\"untrained RMSE: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constant():\n",
    "    def eval(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # Always return 5.81...\n",
    "        return torch.ones((x.shape[0], 1)).to(device) * np.mean(y_train)\n",
    "\n",
    "rmse = eval_model(Constant())\n",
    "print(f\"constant model RMSE: {round(rmse, 3):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smdJBd6q287-"
   },
   "outputs": [],
   "source": [
    "losses = train_model(baseline_model, 50)\n",
    "\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = eval_model(baseline_model)\n",
    "print(f\"trained RMSE: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KlQB2lY8UdN"
   },
   "outputs": [],
   "source": [
    "samples = 10\n",
    "# first ten examples\n",
    "examples_torch, _ = next(iter(dataloader_test))\n",
    "predicted = baseline_model(examples_torch[:samples])\n",
    "predicted = predicted.detach().cpu().numpy()\n",
    "for idx in range(samples):\n",
    "    print(f\"Predicted: {round(float(predicted[idx][0]), 1)} - Actual: {y_test[idx].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDaE3yXxD27U"
   },
   "source": [
    "### Simple Dropout Model\n",
    "\n",
    "In the following, we start by implementing a linear layer consisting stochastic weights. The output layer is kept as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TY8J6QW8vHCG"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DropoutMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_proba):\n",
    "        super(DropoutMLP, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_proba)\n",
    "        self.hidden_layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(dropout_proba)\n",
    "        self.out_layer = nn.Linear(hidden_dim, 1)\n",
    "        self.act = torch.relu\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # First layer\n",
    "        h = self.hidden_layer1(inputs)\n",
    "        h = self.act(h)\n",
    "        h = self.dropout1(h)\n",
    "        # Second layer\n",
    "        h = self.hidden_layer2(h)\n",
    "        h = self.act(h)\n",
    "        h = self.dropout2(h)\n",
    "        # Output layer\n",
    "        output = self.out_layer(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9CErey5vW84",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dropout_model = DropoutMLP(11, 32, 0.1).to(device)\n",
    "[p.numel() for p in dropout_model.parameters()]\n",
    "#mu, rho, W_output, b_output, batch_norm mu, batch_norm sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9CErey5vW84"
   },
   "outputs": [],
   "source": [
    "losses = train_model(dropout_model, 200)\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "As we now have a predictive distribution instead of a single estimate, we can sample several dropout masks and compute several predictions for each example in the test set. It will allow us to see the distribution mean, variance or display a histogram.\n",
    "\n",
    "However, let us first evaluate the model in a deterministic way, as is traditionnally done with standard dropout (not MC-dropout):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non stochastic, the dropout has a different behavior at test time (weights are multiplied by 1-p)\n",
    "rmse = eval_model(baseline_model)\n",
    "print(f\"trained deterministic network RMSE: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_dropout(model):\n",
    "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('Dropout'):\n",
    "            m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuxe0T3fzVTJ"
   },
   "outputs": [],
   "source": [
    "def compute_predictions(model, n_samples=20):\n",
    "    \"\"\" Compute `n_samples` predictions for each example in the test set\"\"\"\n",
    "    model.eval()\n",
    "    enable_dropout(model) # activate dropout at test time\n",
    "    n_test = len(dataset_test)\n",
    "    dropout_predictions = np.zeros((n_samples, n_test))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        with torch.no_grad():\n",
    "            batch_y = np.squeeze(model(tensor_X_test).cpu().numpy())\n",
    "            dropout_predictions[i] = batch_y\n",
    "\n",
    "    # Calculating mean across multiple MCD forward passes \n",
    "    mean = np.mean(dropout_predictions, axis=0) # shape (n_test)\n",
    "\n",
    "    # Calculating variance across multiple MCD forward passes \n",
    "    variance = np.var(dropout_predictions, axis=0) # shape (n_test)\n",
    "\n",
    "    return dropout_predictions, mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, mean, var = compute_predictions(dropout_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(predictions, targets, idxs):\n",
    "    \"\"\" Display predictions for examples in the test set indexed by the list `idxs`\"\"\"\n",
    "    prediction_mean = np.mean(predictions, axis=0).tolist()\n",
    "    prediction_min = np.min(predictions, axis=0).tolist()\n",
    "    prediction_max = np.max(predictions, axis=0).tolist()\n",
    "    prediction_range = (np.max(predictions, axis=0) - np.min(predictions, axis=0)).tolist()\n",
    "\n",
    "    for idx in idxs:\n",
    "        print(\n",
    "            f\"Predictions mean: {round(prediction_mean[idx], 2)}, \"\n",
    "            f\"min: {round(prediction_min[idx], 2)}, \"\n",
    "            f\"max: {round(prediction_max[idx], 2)}, \"\n",
    "            f\"range: {round(prediction_range[idx], 2)} - \"\n",
    "            f\"Actual: {targets[idx].item()}\"\n",
    "        )\n",
    "    plt.boxplot(predictions[:,idxs])\n",
    "    plt.plot(range(1,11), y_test[idxs], 'r.', alpha=0.8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLqsO83iy2Dl"
   },
   "outputs": [],
   "source": [
    "# Chose 10 random indices in the test set\n",
    "idxs=np.random.choice(range(preds.shape[1]), size=10, replace=False)\n",
    "display_predictions(preds, y_test, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to a single estimate, the empirical mean of the prediction has lower RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for y_hat, y in zip(mean, y_test):\n",
    "    errors.append((y_hat - y)**2)\n",
    "\n",
    "rmse = np.sqrt(np.mean(np.concatenate(errors, axis=None)))\n",
    "print(f\"mean prediction RMSE: {round(rmse, 3):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also verify that our model produces variances that depend on the test example rather than a constant value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(var, bins=40, alpha=0.4, color=\"b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing different values of $p$\n",
    "\n",
    "In the original paper, the author mention different values of $p$, chosen as a hyperparameter. They mention that the results should converge to similar results (i.e. variances) with various values like $p=0.1, p=0.2$.\n",
    "\n",
    "However, they chose $p=0.5$ for the LSTM experiment. In the following, we test several values of $p$. Note that it could be a good idea to increase the number of epochs to ensure convergence (which is slower at higher $p$).\n",
    "\n",
    "We compute here the empirical variance, even though in the original paper, they mention that the variance should be:\n",
    "$$V_{q(y^\\star|x^\\star)} = V^{empirical} + τ^{-1}$$\n",
    "\n",
    "where $τ = \\frac{pl^2}{2N\\lambda}$, with $p$ dropout probability, $l$ a hyperparameter depending on the weight initialization, $N$ the number of data points, and $\\lambda$ the weight decay parameter. In practice, the empirical variance alone is used as the other parameters can be tuned (the weight decay can be arbitrarily small for instance, making $τ^{-1}$ neglectable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances =[]\n",
    "for p in [0.0, 0.01, 0.1, 0.2, 0.4]:\n",
    "    print(f\"training model with p={p}\")\n",
    "    dropout_model = DropoutMLP(11, 32, p).to(device)\n",
    "    losses = train_model(dropout_model, 200)\n",
    "    preds, mean, var = compute_predictions(dropout_model)\n",
    "    variances.append(var)\n",
    "    errors = []\n",
    "    for y_hat, y in zip(mean, y_test):\n",
    "        errors.append((y_hat - y)**2)\n",
    "\n",
    "    rmse = np.sqrt(np.mean(np.concatenate(errors, axis=None)))\n",
    "    print(f\"p={p} mean prediction RMSE: {round(rmse, 3):.3f}\")\n",
    "    print(f\"p={p} average variance: {np.mean(var):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(variances[:]).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.vstack(variances[1:]).T, histtype='step', bins=40, label=[f\"p={p}\" for p in [0.01, 0.1, 0.2, 0.4]], \n",
    "         fill=False, alpha=0.6, linewidth=2, hatch='..');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long run\n",
    "p = 0.2\n",
    "print(f\"training model with p={p}\")\n",
    "dropout_model = DropoutMLP(11, 32, p).to(device)\n",
    "losses = train_model(dropout_model, 1000)\n",
    "preds, mean, var = compute_predictions(dropout_model)\n",
    "errors = []\n",
    "for y_hat, y in zip(mean, y_test):\n",
    "    errors.append((y_hat - y)**2)\n",
    "\n",
    "rmse = np.sqrt(np.mean(np.concatenate(errors, axis=None)))\n",
    "print(f\"p={p} mean prediction RMSE: {round(rmse, 3):.3f}\")\n",
    "print(f\"p={p} average variance: {np.mean(var):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest and largest variances\n",
    "idxs = (np.argsort(var)[0:5]).tolist() + (np.argsort(var)[-5:]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_predictions(preds, y_test, idxs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BayesianDeepWine",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
